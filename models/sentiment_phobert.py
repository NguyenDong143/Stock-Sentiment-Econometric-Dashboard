# ======================================================
# üì¶ PHOBERT SENTIMENT ANALYSIS (WONRAX VERSION)
# ======================================================

import torch
import pandas as pd
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import streamlit as st

# ------------------------------------------------------
# 1Ô∏è‚É£ Load model v√† tokenizer (Wonrax fine-tuned PhoBERT)
# ------------------------------------------------------
MODEL_NAME = "wonrax/phobert-base-vietnamese-sentiment"

@st.cache_resource(show_spinner=False)
def load_phobert_model():
    """Cache PhoBERT model ƒë·ªÉ tr√°nh load l·∫°i m·ªói l·∫ßn ch·∫°y"""
    # S·ª≠ d·ª•ng use_fast=True cho tokenizer nhanh h∆°n
    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_NAME, 
        use_fast=True,  # Tokenizer nhanh h∆°n
        model_max_length=256  # Gi·ªõi h·∫°n ƒë·ªô d√†i input
    )
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)
    model.eval()  # Set eval mode
    
    # T·∫Øt gradient ƒë·ªÉ t·ªëi ∆∞u memory
    for param in model.parameters():
        param.requires_grad = False
    
    return tokenizer, model

def get_model():
    """Lazy getter cho model"""
    return load_phobert_model()

# ------------------------------------------------------
# 2Ô∏è‚É£ Ph√¢n t√≠ch c·∫£m x√∫c cho 1 vƒÉn b·∫£n
# ------------------------------------------------------
def analyze_sentiment(text: str):
    if not isinstance(text, str):
        text = str(text)

    # Lazy load model
    tokenizer, model = get_model()
    
    # Tokenize v·ªõi max_length gi·ªõi h·∫°n
    inputs = tokenizer(
        text, 
        return_tensors="pt", 
        truncation=True, 
        max_length=256,  # Gi·ªõi h·∫°n ƒë·ªô d√†i input
        padding="max_length"
    )
    
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)

    # Map nh√£n sang c·∫£m x√∫c
    label_map = model.config.id2label
    result = {label_map[i]: probs[0][i].item() for i in range(len(probs[0]))}
    return result

# ------------------------------------------------------
# 3Ô∏è‚É£ H√†m x·ª≠ l√Ω DataFrame
# ------------------------------------------------------
def analyze_dataframe(df: pd.DataFrame, column: str):
    if column not in df.columns:
        raise ValueError(f"‚ùå C·ªôt '{column}' kh√¥ng t·ªìn t·∫°i trong DataFrame!")

    df[column] = df[column].fillna("").astype(str)
    results = [analyze_sentiment(text) for text in df[column]]
    return pd.DataFrame(results)

# ------------------------------------------------------
# 4Ô∏è‚É£ H√†m ph√¢n lo·∫°i nhanh cho Streamlit
# ------------------------------------------------------
def classify_sentiment(texts):
    if isinstance(texts, str):
        texts = [texts]

    results = []
    for text in texts:
        output = analyze_sentiment(text)
        label = max(output, key=output.get).lower()

        if "neg" in label:
            results.append(-1)
        elif "neu" in label:
            results.append(0)
        else:
            results.append(1)
    return results

# ------------------------------------------------------
# 5Ô∏è‚É£ Test nhanh
# ------------------------------------------------------
if __name__ == "__main__":
    text = "Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n gi·∫£m m·∫°nh, kh·ªëi ngo·∫°i b√°n r√≤ng h√†ng trƒÉm t·ª∑ ƒë·ªìng."
    print(analyze_sentiment(text))
